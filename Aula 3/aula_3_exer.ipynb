{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecc521b-cf52-4003-b5c0-933dfbbec06a",
   "metadata": {},
   "source": [
    "# Implementação e Exercícios - Deep Learning I\n",
    "\n",
    "Vamos começar implementando algumas funções de ativação e analisar seu comportamento. Para isso, vamos usar uma função auxiliar que permitirá a visualização dessas funções:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8300b9-ceb8-46eb-9280-86e82007dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e7697-f74b-46eb-933f-16aba7e07263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "def plot(func, yaxis=(-1.4, 1.4)):\n",
    "    plt.ylim(yaxis)\n",
    "    plt.locator_params(nbins=5)\n",
    "    plt.xticks(fontsize = 14)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.axhline(lw=1, c='black')\n",
    "    plt.axvline(lw=1, c='black')\n",
    "    plt.grid(alpha=0.4, ls='-.')\n",
    "    plt.box(on=None)\n",
    "    plt.plot(x, func(x), c='r', lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e04a4-5aed-4dad-b5e6-080173dc83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vetor contendo dados para plotar as funções\n",
    "x = np.arange(-5, 5, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684eb6f-6580-4a95-ba25-83d9c11bf99a",
   "metadata": {},
   "source": [
    "## Binary Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b0a11-146d-4d98-a38b-4bdbf817a789",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x) = \\left\\{\n",
    "        \\begin{array}{lll}\n",
    "            0 & for & x \\leq 0  \\\\\n",
    "            1 & for & x > 0\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988efe40-b673-403b-ad42-9f8b79626929",
   "metadata": {},
   "source": [
    "$$\n",
    "f'(x) = \\left\\{\n",
    "        \\begin{array}{lll}\n",
    "            0 & for & x \\neq 0  \\\\\n",
    "            ? & for & x = 0\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f85da16-d2b3-403f-b883-4626a1d705ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_step = np.vectorize(lambda x: 1 if x > 0 else 0, otypes=[np.float64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc0c21-3e57-4294-93b3-e98aae4d2ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(binary_step, yaxis=(-0.4, 1.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f0604-f036-403e-81af-8fe18cfaef4f",
   "metadata": {},
   "source": [
    "## Hyperbolic Tangent, TanH\n",
    "\n",
    "Essa função normaliza o output de cada neurônio entre [-1,1]. Entretanto, ela sofre do problema conhecido como *vanishing gradient*, ou seja, quase não produz mudanças na predição para valores muito grandes ou muito pequenos de inputs, fazendo com a rede deixe de aprender. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b237b0-d1eb-42d0-b15d-42b66f342ad3",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x)={\\frac {2}{1+e^{-2x}}}-1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474116e-507b-4dab-a921-e10e53b917a1",
   "metadata": {},
   "source": [
    "$$\n",
    "f'(x)=1-f(x)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80729db5-216f-463d-a528-322a11f51346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return 2 / (1 + np.exp(-2 * x)) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b363b15-f35a-443a-9fbb-4ab78264f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b985dd-0b13-4b20-84e6-36f0b964e8db",
   "metadata": {},
   "source": [
    "## Rectified Linear Units, ReLU\n",
    "Nesta função, os outputs podem variar de 0 até infinito quando o input é positivo, mas quando o input é 0 ou negativo, a função retorna como output 0 e isso pode atrapalhar no cálculo do *backpropagation*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898190e0-416f-42f9-8251-bb62e9ea67b3",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x) = \\left\\{\n",
    "        \\begin{array}{lll}\n",
    "            0 & for & x \\leq 0  \\\\\n",
    "            x & for & x > 0\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185580b2-97f0-4939-a614-40208eded2e0",
   "metadata": {},
   "source": [
    "$$\n",
    "f'(x) = \\left\\{\n",
    "        \\begin{array}{lll}\n",
    "            0 & for & x \\leq 0  \\\\\n",
    "            1 & for & x > 0\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed052c-7b29-4f6b-86ea-c4eb227625df",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = np.vectorize(lambda x: x if x > 0 else 0, otypes=[np.float64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a01bb2-bd4c-42ef-9e9b-1382b71217ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(relu, yaxis=(-0.4, 1.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf560632-68f6-48f0-9caf-04016fa68d07",
   "metadata": {},
   "source": [
    "## Leaky Rectified Linear Units, Leaky ReLU\n",
    "A *Leaky ReLU* foi criada para resolver o problema da ReLU, ou seja, permitir que o *backpropagation* execute sem erros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e082bc-d69c-49d1-a1f7-76b0d3e3ad70",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x) = \\left\\{\n",
    "        \\begin{array}{lll}\n",
    "            ax & for & x \\leq 0  \\\\\n",
    "            x & for & x > 0\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e1005-a67a-4978-a3c5-c105a9eb6c8c",
   "metadata": {},
   "source": [
    "$$\n",
    "f'(x) = \\left\\{\n",
    "        \\begin{array}{lll}\n",
    "            a & for & x \\leq 0  \\\\\n",
    "            1 & for & x > 0\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf23d7b-6784-46a3-99e2-881d71f25faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = np.vectorize(lambda x: max(0.1 * x, x), otypes=[np.float64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee71cc-c0fb-4641-9419-01d579d23751",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(leaky_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8934d-0883-417a-bcfc-e3e0050899e1",
   "metadata": {},
   "source": [
    "# ToDo 1\n",
    "\n",
    "A função sigmoid é uma das mais usadas para problemas em geral. Baseado na equação abaixo, implemente uma função que calcule a sigmoid. Use a função plot para plotar os valores usando a variável *x* como input.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf37ee-e8c9-4cff-a047-b74a8084a6e3",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x)={\\frac {1}{1+e^{-x}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16a621-09c1-4891-98cd-c563b2bbb181",
   "metadata": {},
   "source": [
    "$$\n",
    "f'(x)=f(x)(1-f(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1a478-a784-40dd-bb5b-ea586cc3f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b08a5-af70-47a9-9cd3-d7bf5dc3d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sigmoid, yaxis=(-0.4, 1.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f87568-ca33-49bd-8511-57d502345590",
   "metadata": {},
   "source": [
    "### Perguntas:\n",
    "\n",
    "1. Essas funções podem ser usadas tanto nas camadas ocultas quanto nas camadas de saída?\n",
    "\n",
    "2. Como determinar a função a ser usada? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd902a3-f651-4d5c-ac54-6d065be9b5df",
   "metadata": {},
   "source": [
    "# Gradiente Descendente\n",
    "Agora, vamos implementar as funções básicas do algoritmo Gradiente Descendente e testá-las num dataset pequeno. Antes, porém, vamos começar com algumas funções que nos auxiliarão a plotar e visualizar os dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bf124-544e-4df7-b24c-c59d72306679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#funcão para visualizar os dados a serem classificados\n",
    "def plot_points(X, y):\n",
    "    admitted = X[np.argwhere(y==1)]\n",
    "    rejected = X[np.argwhere(y==0)]\n",
    "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'blue', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'red', edgecolor = 'k')\n",
    "\n",
    "# plota a fronteira de decisao que o algoritmo encontrou\n",
    "def display(m, b, color='g--'):\n",
    "    plt.xlim(-0.05,1.05)\n",
    "    plt.ylim(-0.05,1.05)\n",
    "    x = np.arange(-10, 10, 0.1)\n",
    "    plt.plot(x, m*x+b, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1da64b-5634-425d-8a6b-e2f0fe7fcc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura dos dados\n",
    "data = pd.read_csv('data.csv', header=None)\n",
    "X = np.array(data[[0,1]])\n",
    "y = np.array(data[2])\n",
    "plot_points(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be5fc4-34cd-489b-ada7-fe195f4eef07",
   "metadata": {},
   "source": [
    "# ToDo 2\n",
    "Implemente as seguintes funções vistas em aula:\n",
    "\n",
    "- Sigmoid activation function\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "- Output (prediction) formula\n",
    "\n",
    "$$\\hat{y} = \\sigma(w_1 x_1 + w_2 x_2 + b)$$\n",
    "\n",
    "- Error function\n",
    "\n",
    "$$Error(y, \\hat{y}) = - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})$$\n",
    "\n",
    "- The function that updates the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i + \\alpha (y - \\hat{y}) x_i$$\n",
    "\n",
    "$$ b \\longrightarrow b + \\alpha (y - \\hat{y})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c1837-cf4b-475e-8958-701c457062ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resposta\n",
    "def sigmoid(x):\n",
    "    pass\n",
    "\n",
    "def output_formula(features, weights, bias):\n",
    "    pass\n",
    "\n",
    "def error_formula(y, output):\n",
    "    pass\n",
    "\n",
    "def update_weights(x, y, weights, bias, learnrate):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe42f4-165a-4c8b-bd96-a5860f39dd7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# função auxiliar para treinar a rede neural. Ele itera o gradiente descendente sobre todos os dados para um determinado número\n",
    "# de épocas. Também plota os dados e a fronteira de decisão encontrada. \n",
    "np.random.seed(44)\n",
    "\n",
    "epochs = 100\n",
    "learnrate = 0.01\n",
    "\n",
    "def train(features, targets, epochs, learnrate, graph_lines=False):\n",
    "    \n",
    "    errors = []\n",
    "    n_records, n_features = features.shape\n",
    "    last_loss = None\n",
    "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "    bias = 0\n",
    "    for e in range(epochs):\n",
    "        del_w = np.zeros(weights.shape)\n",
    "        for x, y in zip(features, targets):\n",
    "            weights, bias = update_weights(x, y, weights, bias, learnrate)\n",
    "        \n",
    "        # imprimindo o erro no conjunto de treino\n",
    "        out = output_formula(features, weights, bias)\n",
    "        loss = np.mean(error_formula(targets, out))\n",
    "        errors.append(loss)\n",
    "        if e % (epochs / 10) == 0:\n",
    "            print(\"\\n========== Epoch\", e,\"==========\")\n",
    "            if last_loss and last_loss < loss:\n",
    "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "            else:\n",
    "                print(\"Train loss: \", loss)\n",
    "            last_loss = loss\n",
    "            \n",
    "            # convertende o output (float) para booleano, visto que é classificação binária\n",
    "            predictions = out > 0.5\n",
    "            \n",
    "            accuracy = np.mean(predictions == targets)\n",
    "            print(\"Accuracy: \", accuracy)\n",
    "        if graph_lines and e % (epochs / 100) == 0:\n",
    "            display(-weights[0]/weights[1], -bias/weights[1])\n",
    "            \n",
    "\n",
    "    # Fronteira de decisão\n",
    "    plt.title(\"Solution boundary\")\n",
    "    display(-weights[0]/weights[1], -bias/weights[1], 'black')\n",
    "\n",
    "    # dados\n",
    "    plot_points(features, targets)\n",
    "    plt.show()\n",
    "\n",
    "    # erro\n",
    "    plt.title(\"Error Plot\")\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Error')\n",
    "    plt.plot(errors)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4476d-0d98-44f6-bdf0-fdeb63a0ae25",
   "metadata": {},
   "source": [
    "Vamos treinar o algoritmo.\n",
    "\n",
    "Quando executamos a função, obtemos o seguinte:\n",
    "\n",
    "* 10 atualizações com o valor atual da loss e acurácia\n",
    "* Um plot com os dados e algumas fronteiras de decisão encontradas. A final está em **preto**. Observe como as linhas vão se aproximando da solução ótima conforme o número de épocas vai passando. \n",
    "* Um plot do erro. Observe como o valor reduz a cada época. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c006a4-0cec-42a7-87a1-36a48d12eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X, y, epochs, learnrate, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e01872-3102-44d1-8551-1bbf2a968919",
   "metadata": {},
   "source": [
    "# Usando Scikit-Learn\n",
    "\n",
    "No dia a dia, é mais prático usar soluções já implementadas e otimizadas, principalmente quando lidamos com datasets grandes. Nesse sentido, a Scikit-Learn se torna uma grande aliada. Para entendermos como ela pode nos auxiliar, vamos ver um caso prático simples e, depois, implementar uma solução para um problema bastante conhecido em Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa7080-4914-4ec6-aba6-eeb425fbf771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe77dd-30a8-43a2-aae0-970387dd1b6c",
   "metadata": {},
   "source": [
    "Vamos carregar o conjunto de dados no qual trabalharemos. O código abaixo o carregará nas variáveis X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962c2e6-cdaf-43cd-aa69-435ee95bd6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_planar_dataset()\n",
    "Y = Y[0] #neste dataset Y tem uma dimensao a mais, vamos remove-la\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15538085-34bd-415b-8a00-df6dfe7fb89c",
   "metadata": {},
   "source": [
    "Observe que nossa base de dados contém duas características (X1 e X2) e o rótulo (vermelho:0 e roxo:1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770cf63a-4c5d-4cab-9ad0-e90198c57b30",
   "metadata": {},
   "source": [
    "Vamos plotá-lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c65df-bc06-4fc2-88ac-23378723e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494a9a8-ac82-41b5-ba45-4064a6deffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[0, :], X[1, :], c=Y, s=40, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f9bc4-7291-4993-bf05-009b5339f5e7",
   "metadata": {},
   "source": [
    "Observe que este problema é bastante complexo para conseguirmos separar os pontos azuis dos vermelhos com apenas uma linha, como faríamos com um modelo linear simples. Para efeitos de ilustração, vamos tentar empregar uma regressão logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df271618-99d8-4fea-b5f4-933b6c0a934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.linear_model.LogisticRegressionCV()\n",
    "clf.fit(X.T, Y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af0314-1fca-432d-9df2-3e271a2a6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
    "plt.title(\"Regressão Logística\")\n",
    "\n",
    "LR_predictions = clf.predict(X.T)\n",
    "print ('Taxa de acerto da Regressão Logística: %f ' % float(np.mean(LR_predictions == Y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1d6b72-9218-4ef5-ada9-aa5017c21039",
   "metadata": {},
   "source": [
    "Para casos como este precisamos de modelos mais complexos, com superfícies de decisões não lineares. Como as Redes Neurais podem ser vistas como um conjunto de funções lineares combinadas, elas nos possibilitam obter fronteiras de decisão mais complexas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a8f41-5283-4f27-8e6a-f87fbff3076e",
   "metadata": {},
   "source": [
    "Vamos treinar o modelo Neural abaixo para vermos se obtemos um resultado melhor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba9f84-af7e-42fa-9d00-43e83866e256",
   "metadata": {},
   "source": [
    "<img src=\"imagens/simple_nn.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc556f57-7a05-4f20-a87b-b0567a712240",
   "metadata": {},
   "source": [
    "Matematicamente, para um exemplo $x^{(i)}$ temos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb86a3-0fae-4dd7-b727-f7b64f6534be",
   "metadata": {},
   "source": [
    "$\n",
    "z^{[1](i)}=W^{[1]}x^{[1](i)}+b^{[1](i)}\\\\\n",
    "a^{[1](i)} = tanh(z^{[1](i)})\\\\\n",
    "z^{[2](i)} = W^{[2]}a^{[1](i)}+b^{[2](i)}\\\\\n",
    "\\hat{y }^{(i)} = a^{[2](i)} = \\sigma(z^{[2](i)})\\\\\n",
    "\\begin{equation}\n",
    "  y^{(i)}_{predito} ==\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    0, & \\text{se}\\ a^{[2](i)} > 0.5\\\\\n",
    "    1, & \\text{caso contrário}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} \n",
    "\\tag{1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d7a8d-214b-4253-8e7f-9e32e05070db",
   "metadata": {},
   "source": [
    "Dado os valores preditos, podemos calcular a função de custo por:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8ad6e-34d2-482e-81ea-f344a6e65f2e",
   "metadata": {},
   "source": [
    "$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large \\right) \\small \\tag{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f96e3-cd54-4242-822e-1bbe5e6abae8",
   "metadata": {},
   "source": [
    "O Scikit-learn nos oferece um pacote para trabalharmos com redes Perceptron, para isso definimos a arquitetura da rede como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338bcc94-4832-4646-9471-7b000d603ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(4, 1), activation='tanh', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fc0a8-8aed-455f-b2b3-442f40fd44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X.T, Y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cb4bf2-f67b-4657-b6ad-9437615233e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
    "plt.title(\"Rede Neural\")\n",
    "\n",
    "NN_predictions = clf.predict(X.T)\n",
    "print ('Taxa de acerto da Rede Neural: %f ' % float(np.mean(NN_predictions == Y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92db3b-ab09-498c-ad9e-d337de61029c",
   "metadata": {},
   "source": [
    "Observe que com este modelo conseguimos construir uma superfície de decisão um pouco \"curva\" no espaço $R^2$, já que não estamos mais trabalhando com modelos lineares. Com isso aumentamos nossa taxa de acerto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf61cf75-33d1-4321-863d-322ce14e88d8",
   "metadata": {},
   "source": [
    "Vamos tentar modelos mais complexos para observarmos esse comportamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab280d3-fb99-47b6-ba7c-34791203af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(10, 8, 4, 2), activation='relu', random_state=42)\n",
    "clf.fit(X.T, Y.T)\n",
    "plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
    "plt.title(\"Rede Neural\")\n",
    "\n",
    "NN_predictions = clf.predict(X.T)\n",
    "print ('Taxa de acerto da Rede Neural: %f ' % float(np.mean(NN_predictions == Y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050631c-32bc-4430-b48f-354ce6666d8d",
   "metadata": {},
   "source": [
    "Um hiper parâmetro muito importante a ser configurado em um NN é o learning_rate. Caso ele seja muito baixo, a rede necessitará de muitas interações para convergir (muitas vezes milhões), o que inviabiliza o projeto. Porém, se ele for muito alto pode haver um \"salto\" do mínimo da função pelo gradiente, impossibilitando a convergência do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4308357a-3764-4c53-8d12-851023219977",
   "metadata": {},
   "source": [
    "<img src=\"imagens/sgd.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266a6465-0759-4d26-ae6d-73849103ee05",
   "metadata": {},
   "source": [
    "<img src=\"imagens/sgd_bad.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476493c2-4e9b-46bc-a8fa-9fbf48757bfd",
   "metadata": {},
   "source": [
    "Vamos testar no nosso exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c9029-109d-431c-a702-7ba2926e69dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(4, 4), activation='tanh', random_state=42, learning_rate_init=10.0)\n",
    "clf.fit(X.T, Y.T)\n",
    "plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
    "plt.title(\"Rede Neural\")\n",
    "\n",
    "NN_predictions = clf.predict(X.T)\n",
    "print ('Taxa de acerto da Rede Neural: %f ' % float(np.mean(NN_predictions == Y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0e18c-604a-4728-88d8-7be54137b68d",
   "metadata": {},
   "source": [
    "Observe que mesmo utilizando um modelo mais complexo, a nossa rede não conseguiu convergir para o mínimo de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf2e437-8d67-40f5-8bdc-cf180090ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(4, 4), activation='tanh', random_state=42, learning_rate_init=0.00001)\n",
    "clf.fit(X.T, Y.T)\n",
    "plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
    "plt.title(\"Rede Neural\")\n",
    "\n",
    "NN_predictions = clf.predict(X.T)\n",
    "print ('Taxa de acerto da Rede Neural: %f ' % float(np.mean(NN_predictions == Y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcd3dc0-a388-45d3-a1e4-23ab48b65306",
   "metadata": {},
   "source": [
    "O mesmo acontece com uma learning rate muito baixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3bf594-bbee-496d-93a1-1ddadfaadf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(4, 4), activation='tanh', random_state=42, learning_rate_init=0.001)\n",
    "clf.fit(X.T, Y.T)\n",
    "plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
    "plt.title(\"Rede Neural\")\n",
    "\n",
    "NN_predictions = clf.predict(X.T)\n",
    "print ('Taxa de acerto da Rede Neural: %f ' % float(np.mean(NN_predictions == Y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7263e-229e-4827-be46-c6dbf5042c04",
   "metadata": {},
   "source": [
    "Por fim, uma learning rate adequada resulta em um modelo mais preciso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55801412-4f5e-4f89-90e4-177ec4086020",
   "metadata": {},
   "source": [
    "E para prevermos um valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27c402-34a8-4975-aa16-8e3bb86013f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([[2.5, 0.75]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06f82b-a1fd-4bb0-9a40-6ba4ae11b1f1",
   "metadata": {},
   "source": [
    "Assim, nosso ponto $(2.5, 0.75)$ é da classe roxo (ou azul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d7253-9292-45e7-9174-cace30c9a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba([[2.5, 0.75]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f5ff0c-0b6a-40b4-b023-3dd88fde2e3c",
   "metadata": {},
   "source": [
    "A probabilidade para a classe vermelha é 0.32 e para a roxa 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5e135-9642-4c19-9dd1-faea9fc586f3",
   "metadata": {},
   "source": [
    "# ToDo 3\n",
    "Agora é hora de usar esse conhecimento que acabamos de obter e aplicá-lo num conjunto de dados real e mais complexo. Vamos usar o dataset [MNIST](https://en.wikipedia.org/wiki/MNIST_database).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb874bc-19a2-4878-8063-c8c2eda02ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29004bc5-9a01-439b-b833-e4c3cf9575db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#como o dataset foi criado em Python 2, é necessário o encoding latin1 para carregá-lo em Python 3\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c5f9e-d243-454a-8889-f7995cd35025",
   "metadata": {},
   "source": [
    "O dataset é composto de 70k exemplos, divididos em 50k para treino, 10k para validação e 10k para teste. Cada exemplo é uma imagem 28x28 em escala de cinza contendo um dígito. Vamos ver alguns exemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420575b6-57e2-4f7c-b4ae-fbcc635d9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random examples\n",
    "examples = np.random.randint(10000, size=8)\n",
    "n_examples = len(examples)\n",
    "plt.figure()\n",
    "for ix_example in range(n_examples):\n",
    "    tmp = np.reshape(train_set[0][examples[ix_example],:], [28,28])\n",
    "    ax = plt.subplot(1,n_examples, ix_example + 1)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    plt.title(str(train_set[1][examples[ix_example]]))\n",
    "    plt.imshow(tmp, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e9ad5-d69b-4416-a9ee-6bbdb7753629",
   "metadata": {},
   "source": [
    "Manipulando o conjunto de treino e teste. Aqui, não vamos usar o conjunto de validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a191d8-ca80-4ff7-a0b4-0cd80133f7a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "train_X = train_set[0]\n",
    "train_y = train_set[1]\n",
    "print('Shape of training set: ' + str(train_X.shape))\n",
    "\n",
    "# change y [1D] to Y [2D] sparse array coding class\n",
    "n_examples = len(train_y)\n",
    "labels = np.unique(train_y)\n",
    "train_Y = np.zeros((n_examples, len(labels)))\n",
    "for ix_label in range(len(labels)):\n",
    "    # Find examples with with a Label = lables(ix_label)\n",
    "    ix_tmp = np.where(train_y == labels[ix_label])[0]\n",
    "    train_Y[ix_tmp, ix_label] = 1\n",
    "\n",
    "\n",
    "# Test data\n",
    "test_X = test_set[0]\n",
    "test_y = test_set[1] \n",
    "print('Shape of test set: ' + str(test_X.shape))\n",
    "\n",
    "# change y [1D] to Y [2D] sparse array coding class\n",
    "n_examples = len(test_y)\n",
    "labels = np.unique(test_y)\n",
    "test_Y = np.zeros((n_examples, len(labels)))\n",
    "for ix_label in range(len(labels)):\n",
    "    # Find examples with with a Label = lables(ix_label)\n",
    "    ix_tmp = np.where(test_y == labels[ix_label])[0]\n",
    "    test_Y[ix_tmp, ix_label] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d47d7f-826f-4e8f-b704-5a98975a4e22",
   "metadata": {},
   "source": [
    "1. Defina os hiperparâmetros da rede neural e instancie um modelo MLP da scikit learn:\n",
    "    * número de camadas\n",
    "    * nós em cada camada\n",
    "    * função de ativação\n",
    "    \n",
    "**Dica**: para definir a quantidade de nós em cada camada pense no formato dos dados de entrada e quantas saídas deverá ter a rede. As camadas ocultas podem ter valores arbitrários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05812519-57c0-46f3-90bd-36b843e856cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6772d650-b11b-4c8a-9cbe-798f8f1813f0",
   "metadata": {},
   "source": [
    "2. Treine o modelo\n",
    "**Dica**: use train_Y ao invés de train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7921bc-5884-4cf8-b64e-65243a2c7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda27b2-cec9-4c25-9936-44a65f1146fa",
   "metadata": {},
   "source": [
    "3. Faça a predição do conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0b0c5-8832-434a-9085-ce62e19c4ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ff744-106f-4ad2-baa6-bb61a0176d57",
   "metadata": {},
   "source": [
    "4. Imprima o classification report [documentação](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903fa650-6442-46a6-9cf8-1acbc13cb8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resposta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
